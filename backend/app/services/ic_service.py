"""
AI Investment Committee (IC Meeting) Service

 Implements a multi-perspective investment analysis system using four famous investor personas:
 - Cathie Wood (Growth & Disruption)
 - Nancy Pelosi (Power & Policy)
 - Warren Buffett (Deep Value)
 - Charlie Munger (Inversion & Synthesis)

Architecture:
 1. Parallel execution for Cathie + Nancy (independent analyses)
 2. Sequential execution for Warren (reviews Cathie + Nancy)
 3. Final synthesis by Charlie (reviews all three, produces JSON verdict)
"""

import asyncio
import json
import logging
import re
import time
from typing import Dict, Any, Optional

# Import prompts
from app.core.prompts import (
    PROMPT_CATHIE_WOOD,
    PROMPT_NANCY_PELOSI,
    PROMPT_WARREN_BUFFETT,
    PROMPT_CHARLIE_MUNGER,
    VERDICT_MAP,
    CONVICTION_LEVELS
)

# Configure logging
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


# =============================================================================
# Configuration
# =============================================================================

DASHSCOPE_API_URL = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
DEFAULT_TIMEOUT = 120  # seconds (å¢åŠ åˆ° 120 ç§’ä»¥æ”¯æŒæ›´é•¿çš„ max_tokens=2000 å“åº”)
MAX_RETRIES = 3

# Model context limits (ä¿å®ˆä¼°è®¡ï¼Œç•™å‡ºå®‰å…¨è¾¹ç•Œ)
MAX_MODEL_TOKENS = 200000  # qwen-max çš„å®é™…é™åˆ¶æ˜¯ 202750ï¼Œæˆ‘ä»¬ä½¿ç”¨ 200000 ä½œä¸ºå®‰å…¨å€¼
SAFE_TOKEN_LIMIT = 180000  # å®‰å…¨é™åˆ¶ï¼Œç•™å‡º 20% çš„ä½™é‡
MAX_PROMPT_TOKENS = 150000  # å•æ¬¡è¯·æ±‚çš„æœ€å¤§ prompt token æ•°

# Token ä¼°ç®—ç³»æ•°ï¼ˆç²—ç•¥ä¼°è®¡ï¼‰
CHINESE_TOKEN_RATIO = 1.5  # ä¸­æ–‡å­—ç¬¦ â‰ˆ 1.5 tokens/å­—ç¬¦
ENGLISH_TOKEN_RATIO = 0.25  # è‹±æ–‡å•è¯ â‰ˆ 4 tokens/å•è¯
MIXED_TOKEN_RATIO = 1.0    # æ··åˆå†…å®¹çš„å¹³å‡å€¼


# =============================================================================
# Token Management Helpers
# =============================================================================

def estimate_tokens(text: str) -> int:
    """
    ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡ã€‚

    ä½¿ç”¨ç®€å•çš„å¯å‘å¼æ–¹æ³•ï¼š
    - ä¸­æ–‡å­—ç¬¦çº¦å  1.5 tokens/å­—ç¬¦
    - è‹±æ–‡å•è¯çº¦å  0.25 tokens/å•è¯ï¼ˆå³ 4 tokens/å•è¯ï¼‰
    - æ··åˆå†…å®¹å–å¹³å‡å€¼

    Args:
        text: è¦ä¼°ç®—çš„æ–‡æœ¬

    Returns:
        ä¼°ç®—çš„ token æ•°é‡
    """
    if not text:
        return 0

    # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦å’Œéä¸­æ–‡å­—ç¬¦
    chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    total_chars = len(text)

    if total_chars == 0:
        return 0

    # å¦‚æœä¸»è¦æ˜¯ä¸­æ–‡ï¼Œä½¿ç”¨ä¸­æ–‡æ¯”ä¾‹
    if chinese_chars / total_chars > 0.5:
        return int(total_chars * CHINESE_TOKEN_RATIO)
    else:
        # ä¼°ç®—è‹±æ–‡å•è¯æ•°ï¼ˆæŒ‰ç©ºæ ¼åˆ†è¯ï¼‰
        words = len(text.split())
        return int(words * 4)  # è‹±æ–‡çº¦ 4 tokens/å•è¯


def truncate_text_by_tokens(text: str, max_tokens: int) -> str:
    """
    æ ¹æ® token é™åˆ¶æˆªæ–­æ–‡æœ¬ã€‚

    Args:
        text: è¦æˆªæ–­çš„æ–‡æœ¬
        max_tokens: æœ€å¤§ token æ•°é‡

    Returns:
        æˆªæ–­åçš„æ–‡æœ¬
    """
    if not text:
        return text

    current_tokens = estimate_tokens(text)

    if current_tokens <= max_tokens:
        return text

    # éœ€è¦æˆªæ–­çš„æ¯”ä¾‹
    ratio = max_tokens / current_tokens
    target_length = int(len(text) * ratio * 0.9)  # å†ç•™ 10% å®‰å…¨ä½™é‡

    # å°è¯•åœ¨å¥å­è¾¹ç•Œå¤„æˆªæ–­
    truncated = text[:target_length]

    # æŸ¥æ‰¾æœ€åä¸€ä¸ªå¥å·ã€é—®å·æˆ–æ„Ÿå¹å·
    for delimiter in ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', '\n\n']:
        last_pos = truncated.rfind(delimiter)
        if last_pos > target_length * 0.7:  # å¦‚æœæˆªæ–­ç‚¹åœ¨ 70% ä»¥å
            truncated = truncated[:last_pos + len(delimiter)]
            break

    return truncated + "\n\n[...å†…å®¹å·²æˆªæ–­ä»¥ç¬¦åˆæ¨¡å‹é™åˆ¶...]"


def truncate_with_summary(text: str, max_chars: int = 300) -> str:
    """
    å°†é•¿æ–‡æœ¬æˆªæ–­ä¸ºæ‘˜è¦ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ã€‚

    Args:
        text: åŸå§‹æ–‡æœ¬
        max_chars: æœ€å¤§å­—ç¬¦æ•°

    Returns:
        æˆªæ–­åçš„æ‘˜è¦æ–‡æœ¬
    """
    if len(text) <= max_chars:
        return text

    # å°è¯•åœ¨å¥å­è¾¹ç•Œæˆªæ–­
    truncated = text[:max_chars]
    for delimiter in ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', '\n']:
        last_pos = truncated.rfind(delimiter)
        if last_pos > max_chars * 0.7:
            return truncated[:last_pos + len(delimiter)] + "..."

    return truncated + "..."


# =============================================================================
# LLM Client
# =============================================================================

async def call_llm_async(
    prompt: str,
    api_key: str,
    timeout: int = DEFAULT_TIMEOUT
) -> str:
    """
    Call LLM API asynchronously with multi-model fallback.

    ä¼˜å…ˆçº§: qwen -> deepseek -> zhipu (è‡ªåŠ¨é™çº§)

    Args:
        prompt: The prompt to send
        api_key: API key (å…¼å®¹æ—§å‚æ•°ï¼Œç°åœ¨ä½¿ç”¨LLMå·¥å‚)
        timeout: Request timeout in seconds

    Returns:
        LLM response text
    """
    from app.core.llm_factory import LLMFactory

    # Token æ£€æŸ¥ï¼šä½¿ç”¨æ›´ä¿å®ˆçš„ä¼°ç®—
    chinese_chars = sum(1 for c in prompt if '\u4e00' <= c <= '\u9fff')
    non_chinese = len(prompt) - chinese_chars
    estimated_tokens = int(chinese_chars * 2.5 + non_chinese * 0.5)

    logger.info(
        f"[TOKEN_CHECK] Prompt: {len(prompt)} chars, {chinese_chars} Chinese, "
        f"estimated {estimated_tokens} tokens"
    )

    # å¼ºåˆ¶é™åˆ¶
    MAX_CHARS = 60000
    if len(prompt) > MAX_CHARS:
        logger.error(
            f"[TOKEN_LIMIT] Prompt too long: {len(prompt)} chars > "
            f"{MAX_CHARS}, truncating..."
        )
        prompt = prompt[:MAX_CHARS] + "\n\n[...ç”±äºé•¿åº¦é™åˆ¶å·²æˆªæ–­...]"

    # é‡æ–°è®¡ç®—
    chinese_chars = sum(1 for c in prompt if '\u4e00' <= c <= '\u9fff')
    non_chinese = len(prompt) - chinese_chars
    estimated_tokens = int(chinese_chars * 2.5 + non_chinese * 0.5)

    if estimated_tokens > SAFE_TOKEN_LIMIT:
        logger.error(
            f"[TOKEN_LIMIT] Estimated {estimated_tokens} > {SAFE_TOKEN_LIMIT}, "
            f"truncating..."
        )
        target_chars = int(SAFE_TOKEN_LIMIT / 2.5)
        prompt = prompt[:target_chars] + "\n\n[...ç”±äºé•¿åº¦é™åˆ¶å·²æˆªæ–­...]"
        logger.warning(f"[TOKEN_LIMIT] Truncated to {len(prompt)} chars")

    # å¤šæ¨¡å‹é™çº§ç­–ç•¥ (DeepSeek -> Zhipu)
    models_to_try = ["deepseek", "zhipu"]

    for model in models_to_try:
        try:
            logger.info(f"[LLM] ğŸ”„ å°è¯•ä½¿ç”¨ {LLMFactory.NAMES.get(model, model)}...")

            system_prompt = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Aè‚¡æŠ•èµ„åˆ†æä¸“å®¶ã€‚è¯·æŒ‰ç…§è¦æ±‚æ ¼å¼è¿”å›ç»“æœã€‚"

            result = await LLMFactory.fast_reply(
                model=model,
                system=system_prompt,
                user=prompt,
                timeout=timeout
            )

            # æ£€æŸ¥ç»“æœ
            if result and not result.startswith("[é”™è¯¯]"):
                logger.info(f"[LLM] âœ… {LLMFactory.NAMES.get(model, model)} æˆåŠŸ!")
                return result
            else:
                logger.warning(f"[LLM] âŒ {LLMFactory.NAMES.get(model, model)} å¤±è´¥: {result[:100]}")
                continue

        except Exception as e:
            logger.warning(f"[LLM] âŒ {LLMFactory.NAMES.get(model, model)} å¼‚å¸¸: {str(e)[:100]}")
            continue

    # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
    logger.error("[LLM] ğŸ’€ æ‰€æœ‰æ¨¡å‹å‡å¤±è´¥ï¼è¯·æ£€æŸ¥APIå¯†é’¥é…ç½®ã€‚")
    return "Error: æ‰€æœ‰LLMæ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½® (DEEPSEEK_API_KEY, ZHIPU_API_KEY)"


# =============================================================================
# JSON Parsing Helper
# =============================================================================

def extract_agent_score(response: str) -> Dict[str, Any]:
    """
    ä»åˆ†æå¸ˆå“åº”ä¸­æå–scoreå’Œreasoning

    Args:
        response: åˆ†æå¸ˆçš„æ–‡æœ¬å“åº”

    Returns:
        {
            "score": 0-100,
            "reasoning": "æ‘˜è¦æ–‡æœ¬",
            "full_response": "å®Œæ•´å“åº”"
        }
    """
    result = {
        "score": 50,  # é»˜è®¤åˆ†æ•°
        "reasoning": "æ— æ³•è§£æ",
        "full_response": response
    }

    if not response:
        return result

    try:
        # æ–¹æ³•1: å°è¯•æå–JSONæ ¼å¼ï¼ˆæ”¯æŒå¤šè¡Œï¼‰
        # é¦–å…ˆå°è¯•æå–```jsonä»£ç å—ä¸­çš„å†…å®¹
        json_block_pattern = r'```json\s*(.*?)\s*```'
        json_match = re.search(json_block_pattern, response, re.DOTALL | re.IGNORECASE)

        if json_match:
            json_text = json_match.group(1).strip()
        else:
            # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡
            first_brace = response.find('{')
            last_brace = response.rfind('}')
            if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
                json_text = response[first_brace:last_brace + 1]
            else:
                json_text = None

        # è§£æJSON
        if json_text:
            # æ¸…ç†å¯èƒ½çš„å°¾éšé€—å·
            json_text = re.sub(r',(\s*[}\]])', r'\1', json_text)
            parsed = json.loads(json_text)

            if "score" in parsed:
                result["score"] = max(0, min(100, int(parsed["score"])))
            if "reasoning" in parsed:
                result["reasoning"] = parsed["reasoning"][:200]

            logger.info(
                f"Extracted score from JSON: {result['score']}, "
                f"reasoning: {result['reasoning'][:50] if result['reasoning'] else 'N/A'}..."
            )

        # æ–¹æ³•2: å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–
        if result["score"] == 50:  # è¯´æ˜JSONè§£ææ²¡æˆåŠŸ
            score_patterns = [
                r'[è¯„åˆ†è¯„åˆ†][:ï¼š\s]*(\d+)',
                r'(\d+)åˆ†',
                r'score[:ï¼š\s]*(\d+)',
            ]
            for pattern in score_patterns:
                score_match = re.search(pattern, response)
                if score_match:
                    result["score"] = max(0, min(100, int(score_match.group(1))))
                    logger.info(f"Extracted score from pattern: {result['score']}")
                    break

            # æå–ç¬¬ä¸€å¥è¯ä½œä¸ºreasoning
            lines = [line.strip() for line in response.split('\n') if line.strip()]
            if lines:
                # å–ç¬¬ä¸€å¥éJSONè¡Œ
                for line in lines:
                    if (not line.startswith('{') and
                            not line.startswith('[') and
                            not line.startswith('```')):
                        # å»æ‰ç‰¹æ®Šæ ‡è®°
                        clean_line = re.sub(r'```json|```', '', line)
                        result["reasoning"] = clean_line[:200]
                        break

    except Exception as e:
        logger.warning(f"Failed to extract agent score: {e}")

    return result


def clean_and_parse_json(text: str) -> Dict[str, Any]:
    """
    Robust JSON parsing with cleanup for LLM responses.

    Handles:
    - Markdown code blocks (```json ... ```)
    - Leading/trailing whitespace
    - Common JSON formatting issues
    - Fallback to default JSON if parsing fails

    Args:
        text: Raw LLM response text

    Returns:
        Parsed JSON dictionary, or default JSON if parsing fails
    """
    default_json = {
        "final_verdict": "HOLD",
        "conviction_level": 3,
        "key_considerations": ["æ— æ³•è§£æAIå“åº”ï¼Œå»ºè®®äººå·¥å¤æ ¸"],
        "invert_risks": ["AIåˆ†æå¤±è´¥é£é™©"],
        "synthesis": "ç”±äºæŠ€æœ¯åŸå› ï¼Œæ— æ³•ç”Ÿæˆç»¼åˆåˆ†æã€‚"
    }

    if not text:
        logger.warning("Empty text provided to clean_and_parse_json")
        return default_json

    try:
        # Step 1: Remove markdown code blocks
        # Pattern 1: ```json ... ```
        json_pattern = r'```json\s*(.*?)\s*```'
        match = re.search(json_pattern, text, re.DOTALL | re.IGNORECASE)
        if match:
            text = match.group(1)
            logger.info("Extracted JSON from ```json block")

        # Pattern 2: ``` ... ``` (no language specified)
        if not match:
            code_pattern = r'```\s*(.*?)\s*```'
            match = re.search(code_pattern, text, re.DOTALL)
            if match:
                text = match.group(1)
                logger.info("Extracted JSON from ``` block")

        # Step 2: Try to find JSON object boundaries
        # Look for first { and last }
        first_brace = text.find('{')
        last_brace = text.rfind('}')

        if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
            text = text[first_brace:last_brace + 1]
            logger.info("Extracted JSON using brace boundaries")

        # Step 3: Clean common issues
        # Remove trailing commas before closing brackets/braces
        text = re.sub(r',(\s*[}\]])', r'\1', text)

        # Step 4: Parse JSON
        parsed = json.loads(text)
        logger.info("Successfully parsed JSON response")
        return parsed

    except json.JSONDecodeError as e:
        logger.error(f"JSON parsing failed: {str(e)}")
        logger.error(f"Text that failed to parse: {text[:500]}...")
        return default_json
    except Exception as e:
        logger.error(f"Unexpected error in clean_and_parse_json: {str(e)}")
        return default_json


# =============================================================================
# IC Meeting Service
# =============================================================================

async def conduct_meeting(
    symbol: str,
    stock_name: str,
    current_price: float,
    context: Optional[Dict[str, Any]] = None,
    api_key: Optional[str] = None
) -> Dict[str, Any]:
    """
    Conduct an AI Investment Committee meeting for a given stock.

    Meeting Flow:
    1. Parallel: Cathie Wood + Nancy Pelosi analyze independently
    2. Sequential: Warren Buffett reviews Cathie + Nancy's views
    3. Final: Charlie Munger synthesizes all views into JSON verdict

    Args:
        symbol: Stock symbol (e.g., "600519")
        stock_name: Stock name (e.g., "è´µå·èŒ…å°")
        current_price: Current stock price
        context: Additional context (industry, market cap, etc.)
        api_key: DashScope API key (optional, reads from env if not provided)

    Returns:
        Dictionary containing:
        - symbol: Stock symbol
        - cathie_wood: Analysis from Cathie Wood
        - nancy_pelosi: Analysis from Nancy Pelosi
        - warren_buffett: Analysis from Warren Buffett
        - final_verdict: Parsed JSON verdict from Charlie Munger
        - verdict_chinese: Chinese translation of verdict
        - conviction_stars: Star rating for conviction
        - error: Error message if any step failed
    """
    logger.info(f"Starting IC meeting for {symbol} ({stock_name})")

    # ========================================================================
    # [TIMING] å¼€å§‹è®¡æ—¶
    # ========================================================================
    timing_total_start = time.time()
    timing_prepare_start = time.time()
    if context is None:
        context = {}
        # å¦‚æœcontextä¸ºç©ºï¼Œä¸»åŠ¨è·å–è´¢åŠ¡æ•°æ®
        from app.services.market_service import calculate_financial_metrics
        financial_metrics = calculate_financial_metrics(symbol)
        # ä¿®å¤: metrics æ•°æ®åœ¨ 'metrics' å­—æ®µä¸­ï¼Œä¸æ˜¯ç›´æ¥åœ¨æ ¹çº§åˆ«
        context.update(financial_metrics.get('metrics', {}))
        # åŒæ—¶æ·»åŠ  market å’Œ symbol
        context['market'] = financial_metrics.get('market', 'A')
        context['symbol'] = financial_metrics.get('symbol', symbol)
        logger.info(
            f"[ENHANCED] Fetched financial metrics: "
            f"ROE={context.get('roe')}, PE={context.get('pe_ratio')}"
        )

    base_context = f"""
Stock: {symbol} - {stock_name}
Current Price: {current_price}
Industry: {context.get('industry', 'N/A')}
Market Cap: {context.get('market_cap', 'N/A')}

=== Value Metrics (Warren Buffett) ===
PE Ratio: {context.get('pe_ratio', 'N/A')}
PB Ratio: {context.get('pb_ratio', 'N/A')}
ROE: {context.get('roe', 'N/A')}
Debt-to-Equity: {context.get('debt_to_equity', 'N/A')}
FCF Yield: {context.get('fcf_yield', 'N/A')}

=== Growth Metrics (Cathie Wood) ===
Revenue Growth (CAGR): {context.get('revenue_growth_cagr', 'N/A')}
PEG Ratio: {context.get('peg_ratio', 'N/A')}
R&D Intensity: {context.get('rd_intensity', 'N/A')}

=== Technical & Momentum Metrics (Nancy Pelosi) ===
RSI (14): {context.get('rsi_14', 'N/A')}
Volume Status: {context.get('volume_status', 'N/A')}
Volume Change %: {context.get('volume_change_pct', 'N/A')}%
Turnover Rate: {context.get('turnover_rate', 'N/A')}%
MA20 Status: {context.get('ma20_status', 'N/A')}
Health Score: {context.get('health_score', 'N/A')}/100
Action Signal: {context.get('action_signal', 'N/A')}
Bollinger Band Width: {context.get('bb_width', 'N/A')}
VWAP (20-day): {context.get('vwap_20d', 'N/A')}
Bollinger Position: {context.get('bollinger_position', 'N/A')}
"""

    # æ·»åŠ æ•°æ®è´¨é‡è¯´æ˜
    if context.get('data_quality_notes'):
        base_context += f"""
=== Data Quality Notes ===
{context.get('data_quality_notes')}

IMPORTANT: When data shows as estimated/calculated, please acknowledge this in your
analysis and use it with appropriate caution. Make reasonable judgments based on available
data rather than simply stating "data unavailable".
"""

    # æ£€æŸ¥å¹¶æˆªæ–­ base_contextï¼ˆé¢„ç•™è¶³å¤Ÿç©ºé—´ç»™ promptï¼‰
    base_context_tokens = estimate_tokens(base_context)
    if base_context_tokens > 5000:
        logger.warning(f"Base context too large: {base_context_tokens} tokens, truncating...")
        base_context = truncate_text_by_tokens(base_context, 3000)
        base_context_tokens = estimate_tokens(base_context)

    # Debug: Print the context to see what data is being sent to AI
    print(f"[DEBUG] IC Meeting Context for {symbol}:")
    print(base_context)
    print(f"[DEBUG] Context keys: {list(context.keys())}")

    # =============================================================================
    # NEW: Enhanced Context Injection (Anti-Hallucination Data)
    # =============================================================================
    injection_context = ""
    profile_data = None
    news_result = None

    try:
        # 1. Fetch Tushare Profile (Official Company Identity) - with timeout
        logger.info(f"[ENHANCED] Fetching Tushare profile for {symbol}...")
        from app.services.market_service import get_stock_main_business_tushare

        # Add timeout wrapper for Tushare call
        # Note: signal.alarm not supported on Windows, using direct call
        def timeout_handler(signum, frame):
            raise TimeoutError("Tushare API call timed out")

        try:
            # Windows doesn't support signal.alarm, so we'll use a different approach
            # Just call it directly - if it hangs, we'll catch it in the except
            profile_data = get_stock_main_business_tushare(symbol)
            logger.info("[ENHANCED] Tushare profile fetched successfully")

            # è·å–å½“å‰ä»·æ ¼ï¼ˆå¦‚æœä¼ å…¥çš„ price æ— æ•ˆæ‰ä½¿ç”¨ stock_info çš„å€¼ï¼‰
            from app.services.data_fetcher import DataFetcher
            fetcher = DataFetcher()
            stock_info = fetcher.get_stock_info(symbol)
            fetched_price = stock_info.get("current_price", 0) if stock_info else 0
            # åªæœ‰å½“ä¼ å…¥çš„ current_price æ— æ•ˆæ—¶ï¼Œæ‰ä½¿ç”¨ fetched_price
            if not current_price or current_price <= 0:
                current_price = fetched_price
            logger.info(f"[ENHANCED] Got current price: {current_price} (fetched: {fetched_price})")
        except Exception as tushare_error:
            logger.warning(f"[ENHANCED] Tushare fetch failed: {tushare_error}")
            profile_data = None

        # 2. Fetch Tavily Intelligence (Real-time News Intelligence)
        from app.services.search_service import search_financial_news, format_search_context_for_llm

        logger.info(f"[ENHANCED] Fetching Tavily news for {symbol}...")
        news_result = await search_financial_news(
            symbol=symbol,
            stock_name=stock_name,
            max_results=10
        )
        logger.info(f"[ENHANCED] Tavily search completed: {len(news_result.get('results', []))} results")

        # è§£æ Tavily JSON æ•°æ®
        tavily_context_json = format_search_context_for_llm(news_result, stock_name)
        try:
            tavily_data = json.loads(tavily_context_json)
            tavily_structured = tavily_data.get("tavily_data", {})
            tavily_summary = tavily_data.get("summary", "")

            # æå– Tavily æ•°æ®å­—æ®µ
            tavily_results = tavily_structured.get("results", [])
            tavily_total = tavily_structured.get("total_fetched", 0)
            tavily_time = tavily_structured.get("search_time", "")
            tavily_quality = tavily_structured.get("quality_threshold", 0.4)

            logger.info(
                f"[ENHANCED] Tavily parsed: {tavily_total} fetched, "
                f"{len(tavily_results)} results, quality={tavily_quality}"
            )
        except Exception as e:
            logger.warning(f"[ENHANCED] Failed to parse Tavily JSON: {e}, using raw text")
            tavily_summary = tavily_context_json

        # 3. Build Injection Payload (Appended to User Prompt, NOT System Prompt)
        if profile_data or news_result.get('results'):
            injection_context = """
ã€=== æ–°å¢é«˜ç»´æ•°æ®è¾“å…¥ (Anti-Hallucination) ===ã€‘
"""
            if profile_data:
                injection_context += f"""
1. å…¬å¸å®˜æ–¹èº«ä»½ (Tushare Profile):
   - è‚¡ç¥¨ä»£ç : {profile_data.get('symbol', 'N/A')}
   - è‚¡ç¥¨åç§°: {profile_data.get('name', 'N/A')}
   - æ‰€å±è¡Œä¸š: {profile_data.get('industry', 'N/A')}
   - æ‰€åœ¨åœ°: {profile_data.get('area', 'N/A')}
   - ä¸»è¥ä¸šåŠ¡: {profile_data.get('main_business', 'N/A')}
   - ç»è¥èŒƒå›´: {profile_data.get('business_scope', 'N/A')[:200]}...
"""

            if news_result.get('results'):
                injection_context += f"""
2. å¸‚åœºå®æ—¶æƒ…æŠ¥ (Tavily Search):
{tavily_summary}
"""

            injection_context += """
ã€é‡è¦ã€‘è¯·åŸºäºä»¥ä¸Šæ–°å¢äº‹å®æ•°æ®ï¼Œç»“åˆä½ åŸæœ‰çš„æŠ•èµ„é€»è¾‘è¿›è¡Œåˆ†æã€‚ä¸è¦å‡­ç©ºæƒ³è±¡å…¬å¸ä¸šåŠ¡ï¼Œä»¥Tushareå®˜æ–¹ä¿¡æ¯ä¸ºå‡†ã€‚
"""
            logger.info(f"[ENHANCED] Injected Tushare Profile + Tavily Intel for {symbol}")

    except Exception as e:
        logger.warning(f"[ENHANCED] Failed to fetch anti-hallucination data: {e}")
        injection_context = ""

    # Merge injection context into base context
    enhanced_base_context = base_context + injection_context

    logger.info(f"[TIMING] æ•°æ®å‡†å¤‡å®Œæˆ: {time.time() - timing_prepare_start:.2f}s")

    # =============================================================================
    # Round 1: Parallel Execution (Cathie + Nancy)
    # =============================================================================

    logger.info("Round 1: Parallel execution - Cathie Wood + Nancy Pelosi")

    timing_round1_start = time.time()

    try:
        # Create tasks for parallel execution
        cathie_task = call_llm_async(
            f"{PROMPT_CATHIE_WOOD}\n\n{enhanced_base_context}",
            api_key or ""
        )

        nancy_task = call_llm_async(
            f"{PROMPT_NANCY_PELOSI}\n\n{enhanced_base_context}",
            api_key or ""
        )

        # Execute in parallel
        cathie_response, nancy_response = await asyncio.gather(
            cathie_task,
            nancy_task
        )

        logger.info("Round 1 completed: Received responses from Cathie and Nancy")
        logger.info(f"[TIMING] Round 1 (Cathie+Nancyå¹¶è¡Œ): {time.time() - timing_round1_start:.2f}s")

    except Exception as e:
        logger.error(f"Round 1 failed: {str(e)}")
        cathie_response = f"Error: Cathie Wood analysis failed - {str(e)}"
        nancy_response = f"Error: Nancy Pelosi analysis failed - {str(e)}"

    # =============================================================================
    # Round 2: Sequential Execution (Warren Buffett)
    # =============================================================================

    logger.info("Round 2: Sequential execution - Warren Buffett")

    timing_round2_start = time.time()

    # æ›´æ¿€è¿›åœ°æˆªæ–­å‰ä¸¤è½®å“åº”ï¼Œå‡å°‘ token ä½¿ç”¨
    cathie_summary = truncate_with_summary(cathie_response, 200)
    nancy_summary = truncate_with_summary(nancy_response, 200)

    # è®¡ç®— Warren çš„ prompt é¢„ä¼° token æ•°
    # é¢„ç•™ 2000 for summaries
    warren_prompt_est = (
        estimate_tokens(PROMPT_WARREN_BUFFETT) +
        estimate_tokens(base_context) + 2000
    )

    if warren_prompt_est > MAX_PROMPT_TOKENS:
        logger.warning(
            f"Warren's prompt too large: {warren_prompt_est} tokens, "
            f"further truncating..."
        )
        cathie_summary = truncate_with_summary(cathie_response, 100)
        nancy_summary = truncate_with_summary(nancy_response, 100)

    warren_context = f"""
{enhanced_base_context}

## Previous Analysts' Views (Summarized)

### Cathie Wood (Growth Perspective):
{cathie_summary}

### Nancy Pelosi (Policy Perspective):
{nancy_summary}

## Your Task
Review the summarized perspectives above, then provide your value investing analysis.
**Please be concise** - limit your response to 300 words maximum.
"""

    try:
        warren_response = await call_llm_async(
            f"{PROMPT_WARREN_BUFFETT}\n\n{warren_context}",
            api_key or ""
        )
        logger.info("Round 2 completed: Received response from Warren Buffett")
        logger.info(f"[TIMING] Round 2 (Warren): {time.time() - timing_round2_start:.2f}s")

    except Exception as e:
        logger.error(f"Round 2 failed: {str(e)}")
        warren_response = f"Error: Warren Buffett analysis failed - {str(e)}"

    # =============================================================================
    # Round 3: Final Verdict (Charlie Munger)
    # =============================================================================

    logger.info("Round 3: Final verdict - Charlie Munger")

    timing_round3_start = time.time()

    # è®¡ç®—å¯ç”¨ token é¢„ç®—
    prompt_tokens = estimate_tokens(PROMPT_CHARLIE_MUNGER)
    context_tokens = estimate_tokens(base_context)
    # ç•™å‡º 5000 å®‰å…¨ä½™é‡
    available_for_summaries = (
        MAX_PROMPT_TOKENS - prompt_tokens - context_tokens - 5000
    )

    if available_for_summaries < 1000:
        logger.error(f"Not enough token budget for Charlie: {available_for_summaries}")
        available_for_summaries = 1000  # æœ€å°‘ä¿ç•™ 1000

    # æ¯ä¸ªæ‘˜è¦åˆ†é… 1/3 çš„å¯ç”¨ç©ºé—´
    summary_limit = available_for_summaries // 3

    # ä½¿ç”¨ token æ„ŸçŸ¥çš„æˆªæ–­
    cathie_brief = truncate_text_by_tokens(cathie_response, summary_limit)
    nancy_brief = truncate_text_by_tokens(nancy_response, summary_limit)
    warren_brief = truncate_text_by_tokens(warren_response, summary_limit)

    # è¿›ä¸€æ­¥å‹ç¼©ä¸ºæç®€æ‘˜è¦
    cathie_brief = truncate_with_summary(cathie_brief, 150)
    nancy_brief = truncate_with_summary(nancy_brief, 150)
    warren_brief = truncate_with_summary(warren_brief, 150)

    charlie_context = f"""
{enhanced_base_context}

## IC Meeting Summary (Brief)

### Cathie Wood (Growth & Disruption):
{cathie_brief}

### Nancy Pelosi (Power & Policy):
{nancy_brief}

### Warren Buffett (Deep Value):
{warren_brief}

## Your Task
Review the summarized perspectives above, then provide your FINAL VERDICT in JSON format
as specified in your instructions.

**CRITICAL OUTPUT REQUIREMENTS:**
- Do NOT output markdown formatting (no ```json or ``` blocks)
- Output RAW JSON only
- Keep the "synthesis" field under 50 words
- Keep each "key_consideration" under 20 words
- Keep each "invert_risk" under 15 words
"""

    # æœ€ç»ˆæ£€æŸ¥ Charlie çš„ prompt æ˜¯å¦è¶…è¿‡é™åˆ¶
    final_charlie_prompt = f"{PROMPT_CHARLIE_MUNGER}\n\n{charlie_context}"
    final_token_count = estimate_tokens(final_charlie_prompt)

    if final_token_count > SAFE_TOKEN_LIMIT:
        logger.error(
            f"Charlie's prompt exceeds safe limit: "
            f"{final_token_count} > {SAFE_TOKEN_LIMIT}"
        )
        # ç´§æ€¥æˆªæ–­ï¼šä¿ç•™æ ¸å¿ƒä¸Šä¸‹æ–‡ + ç²¾ç®€çš„å¢å¼ºæ•°æ®
        charlie_context = f"""
Stock: {symbol} - {stock_name}
Current Price: {current_price}

## Key Metrics:
PE: {context.get('pe_ratio', 'N/A')}, ROE: {context.get('roe', 'N/A')}, Growth: {context.get('revenue_growth_cagr', 'N/A')}  # noqa: E501

## Analysts' Key Decisions:
- Cathie Wood: {truncate_with_summary(cathie_response, 50)}
- Nancy Pelosi: {truncate_with_summary(nancy_response, 50)}
- Warren Buffett: {truncate_with_summary(warren_response, 50)}

{injection_context[:300] if injection_context else ""}

Provide your FINAL VERDICT in JSON format. Be concise.
"""

    try:
        charlie_response = await call_llm_async(
            f"{PROMPT_CHARLIE_MUNGER}\n\n{charlie_context}",
            api_key or ""
        )
        logger.info("Round 3 completed: Received response from Charlie Munger")
        logger.info(f"[TIMING] Round 3 (Charlie): {time.time() - timing_round3_start:.2f}s")

        # Parse Charlie's JSON response
        final_verdict = clean_and_parse_json(charlie_response)

    except Exception as e:
        logger.error(f"Round 3 failed: {str(e)}")
        final_verdict = {
            "final_verdict": "HOLD",
            "conviction_level": 3,
            "key_considerations": [f"AIåˆ†æå¤±è´¥: {str(e)}"],
            "invert_risks": ["æŠ€æœ¯æ•…éšœé£é™©"],
            "synthesis": "ç”±äºæŠ€æœ¯åŸå› ï¼Œæ— æ³•å®ŒæˆæŠ•å§”ä¼šä¼šè®®ã€‚"
        }

    # =============================================================================
    # Compile Results
    # =============================================================================

    # Handle both old and new JSON format from Charlie Munger
    # New format: "decision", "conviction", "risk_factors"
    # Old format: "final_verdict", "conviction_level", "invert_risks"
    verdict_key = "decision" if "decision" in final_verdict else "final_verdict"
    conviction_key = "conviction" if "conviction" in final_verdict else "conviction_level"
    risks_key = "risk_factors" if "risk_factors" in final_verdict else "invert_risks"

    # Normalize to old format for backward compatibility
    normalized_verdict = {
        "final_verdict": final_verdict.get(
            verdict_key, final_verdict.get("final_verdict", "HOLD")
        ),
        "conviction_level": final_verdict.get(
            conviction_key, final_verdict.get("conviction_level", 3)
        ),
        "key_considerations": final_verdict.get("key_considerations", []),
        "invert_risks": final_verdict.get(risks_key, final_verdict.get("invert_risks", [])),
        "synthesis": final_verdict.get("synthesis", ""),
        # New fields (if present)
        "score": final_verdict.get("score"),
        "logical_flaws_detected": final_verdict.get("logical_flaws_detected", []),
    }

    verdict_chinese = VERDICT_MAP.get(normalized_verdict["final_verdict"], "æŒæœ‰")
    conviction_level = normalized_verdict["conviction_level"]
    conviction_stars = CONVICTION_LEVELS.get(conviction_level, "***")  # ä½¿ç”¨ASCIIæ˜Ÿå·é¿å…ç¼–ç é—®é¢˜

    # è®¡ç®—æŠ€æœ¯é¢å’ŒåŸºæœ¬é¢å¾—åˆ†
    technical_score = calculate_technical_score(context)
    fundamental_score = calculate_fundamental_score(context)

    # =============================================================================
    # NEW: æå–è§’è‰²è¯„åˆ†å¹¶è®¡ç®—Dashboardåæ ‡
    # =============================================================================
    # æå–ä¸‰ä¸ªè§’è‰²çš„scoreå’Œreasoning
    cathie_score_data = extract_agent_score(cathie_response)
    nancy_score_data = extract_agent_score(nancy_response)
    warren_score_data = extract_agent_score(warren_response)

    # è®¡ç®—å™¨é€»è¾‘ï¼šå°†4ä¸ªè§’è‰²åˆ†æ•°æ˜ å°„åˆ°Dashboardåæ ‡
    # Axis X (Fundamental) = (Warren Buffett * 0.6) + (Nancy Pelosi * 0.4)
    # Axis Y (Trend/Tech) = (Cathie Wood * 0.5) + (Technical Score * 0.5)

    # Xè½´ï¼šåŸºæœ¬é¢ (Warren = ä»·å€¼æƒé‡0.6 + Nancy = å®è§‚/æ”¿ç­–æƒé‡0.4)
    fundamental_x = int((warren_score_data["score"] * 0.6) + (nancy_score_data["score"] * 0.4))
    fundamental_x = max(0, min(100, fundamental_x))  # ç¡®ä¿åœ¨0-100èŒƒå›´å†…

    # Yè½´ï¼šè¶‹åŠ¿/æŠ€æœ¯é¢ (Cathie = æˆé•¿æƒé‡0.5 + Technical = æŠ€æœ¯æƒé‡0.5)
    trend_y = int((cathie_score_data["score"] * 0.5) + (technical_score * 0.5))
    trend_y = max(0, min(100, trend_y))  # ç¡®ä¿åœ¨0-100èŒƒå›´å†…

    logger.info(
        f"[CALCULATOR] Cathie Score: {cathie_score_data['score']}, "
        f"Nancy Score: {nancy_score_data['score']}, "
        f"Warren Score: {warren_score_data['score']}"
    )
    logger.info(
        f"[CALCULATOR] final_x (Fundamental): {fundamental_x}, "
        f"final_y (Trend): {trend_y}"
    )

    # FLUSH immediately
    for handler in logger.handlers:
        handler.flush()

    result = {
        "symbol": symbol,
        "stock_name": stock_name,
        "current_price": current_price,
        "cathie_wood": cathie_response,
        "nancy_pelosi": nancy_response,
        "warren_buffett": warren_response,
        "charlie_munger_raw": charlie_response if 'charlie_response' in locals() else "Error",
        "final_verdict": normalized_verdict,
        "verdict_chinese": verdict_chinese,
        "conviction_level": conviction_level,
        "conviction_stars": conviction_stars,
        "technical_score": technical_score,
        "fundamental_score": fundamental_score,
        "timestamp": context.get("timestamp", ""),
        # NEW: æ·»åŠ è§’è‰²è¯„åˆ†å’ŒDashboardåæ ‡
        "agent_scores": {
            "cathie_wood": cathie_score_data,
            "nancy_pelosi": nancy_score_data,
            "warren_buffett": warren_score_data
        },
        "dashboard_position": {
            "final_x": fundamental_x,  # Axis X: Fundamental (Value * 0.6 + Macro * 0.4)
            "final_y": trend_y        # Axis Y: Trend (Growth * 0.5 + Technical * 0.5)
        }
    }

    logger.info(f"IC meeting completed for {symbol}: {verdict_chinese} {conviction_stars}")
    logger.info(f"[DEBUG] About to return result with {len(result)} keys")
    logger.info(f"[TIMING] === ICæŠ•å§”ä¼šæ€»è€—æ—¶: {time.time() - timing_total_start:.2f}s ===")
    return result


# =============================================================================
# Helper Functions
# =============================================================================

def format_ic_meeting_summary(meeting_result: Dict[str, Any]) -> str:
    """
    Format IC meeting results into a readable text summary.

    Args:
        meeting_result: Result from conduct_meeting()

    Returns:
        Formatted text summary
    """
    lines = [
        "# AIæŠ•å§”ä¼šä¼šè®®çºªè¦",
        "",
        f"**è‚¡ç¥¨ä»£ç **: {meeting_result['symbol']}",
        f"**è‚¡ç¥¨åç§°**: {meeting_result['stock_name']}",
        f"**å½“å‰ä»·æ ¼**: {meeting_result['current_price']}",
        f"**æœ€ç»ˆåˆ¤å†³**: {meeting_result['verdict_chinese']} {meeting_result['conviction_stars']}",
        "",
        "---",
        "",
        "## 1. Cathie Wood (æˆé•¿ä¸é¢ è¦†)",
        "",
        f"{meeting_result['cathie_wood']}",
        "",
        "---",
        "",
        "## 2. Nancy Pelosi (æƒåŠ›ä¸æ”¿ç­–)",
        "",
        f"{meeting_result['nancy_pelosi']}",
        "",
        "---",
        "",
        "## 3. Warren Buffett (æ·±åº¦ä»·å€¼)",
        "",
        f"{meeting_result['warren_buffett']}",
        "",
        "---",
        "",
        "## 4. Charlie Munger (æœ€ç»ˆåˆ¤å†³)",
        "",
        f"**æœ€ç»ˆè§‚ç‚¹**: {meeting_result['verdict_chinese']}",
        f"**ä¿¡å¿ƒç­‰çº§**: {meeting_result['conviction_stars']} ({meeting_result['conviction_level']}/5)",
        "",
        "**å…³é”®è€ƒè™‘å› ç´ **:",
    ]

    for consideration in meeting_result['final_verdict'].get('key_considerations', []):
        lines.append(f"- {consideration}")

    lines.append("")
    lines.append("**åå‘æ€è€ƒé£é™©**:")

    for risk in meeting_result['final_verdict'].get('invert_risks', []):
        lines.append(f"- {risk}")

    lines.append("")
    lines.append(f"**ç»¼åˆé€»è¾‘**: {meeting_result['final_verdict'].get('synthesis', 'N/A')}")

    return "\n".join(lines)


def get_ic_recommendation_summary(meeting_result: Dict[str, Any]) -> str:
    """
    Get a one-line summary of the IC recommendation.

    Args:
        meeting_result: Result from conduct_meeting()

    Returns:
        One-line summary string
    """
    return (
        f"{meeting_result['stock_name']} ({meeting_result['symbol']}): "
        f"{meeting_result['verdict_chinese']} {meeting_result['conviction_stars']} - "
        f"{meeting_result['final_verdict'].get('synthesis', '')[:50]}..."
    )


def _to_float(value: Any) -> float | None:
    """Helper function to convert various types to float, handling percentages and 'N/A'"""
    if value is None or value == 'N/A' or value == '':
        return None
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str):
        # Remove % sign and whitespace
        cleaned = value.replace('%', '').strip()
        try:
            return float(cleaned)
        except ValueError:
            return None
    return None


def calculate_technical_score(context: Dict[str, Any]) -> int:
    """
    æ ¹æ®æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æŠ€æœ¯é¢å¾—åˆ†ï¼ˆ0-100ï¼‰

    Args:
        context: åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„å­—å…¸

    Returns:
        æŠ€æœ¯é¢å¾—åˆ† (0-100)
    """
    score = 50  # åŸºç¡€åˆ†

    try:
        # Health Score (0-100) - æƒé‡ 30%
        health_score = _to_float(context.get('health_score'))
        if health_score is not None:
            score += (health_score - 50) * 0.3

        # RSI (14) - æƒé‡ 20%
        # RSI > 70 è¶…ä¹°ï¼ˆå‡åˆ†ï¼‰ï¼ŒRSI < 30 è¶…å–ï¼ˆåŠ åˆ†ï¼‰ï¼Œ30-70 ç†æƒ³
        rsi = _to_float(context.get('rsi_14'))
        if rsi is not None:
            if 30 <= rsi <= 70:
                score += 10
            elif rsi < 30:
                score += 5  # è¶…å–å¯èƒ½åå¼¹
            else:  # rsi > 70
                score -= 15  # è¶…ä¹°é£é™©

        # MA20 Status - æƒé‡ 15%
        ma20_status = context.get('ma20_status', '')
        if isinstance(ma20_status, str):
            if 'ä»·æ ¼ä½äºå‡çº¿ä¸Šæ–¹' in ma20_status or 'above' in ma20_status.lower():
                score += 15
            elif 'ä»·æ ¼ä½äºå‡çº¿é™„è¿‘' in ma20_status or 'near' in ma20_status.lower():
                score += 5
            else:
                score -= 10

        # Volume Change % - æƒé‡ 15%
        volume_change = _to_float(context.get('volume_change_pct'))
        if volume_change is not None:
            if volume_change > 50:
                score += 10
            elif volume_change > 20:
                score += 5
            elif volume_change < -20:
                score -= 10

        # Bollinger Band Width - æƒé‡ 10%
        # å®½åº¦è¿‡çª„å¯èƒ½é¢„ç¤ºçªç ´ï¼Œå®½åº¦è¿‡å®½å¯èƒ½å›è°ƒ
        bandwidth = _to_float(context.get('bandwidth'))
        if bandwidth is not None:
            if bandwidth < 0.05:
                score += 8  # å¯èƒ½çªç ´
            elif bandwidth > 0.2:
                score -= 5  # å¯èƒ½å›è°ƒ

        # VWAP vs Price - æƒé‡ 10%
        vwap = _to_float(context.get('vwap_20'))
        current_price = _to_float(context.get('current_price'))
        if vwap is not None and current_price is not None:
            if current_price > vwap:
                score += 10
            elif current_price < vwap * 0.95:
                score -= 10

    except Exception as e:
        logger.warning(f"Error calculating technical score: {e}")

    return max(0, min(100, int(score)))


def calculate_fundamental_score(context: Dict[str, Any]) -> int:
    """
    æ ¹æ®åŸºæœ¬é¢æŒ‡æ ‡è®¡ç®—åŸºæœ¬é¢å¾—åˆ†ï¼ˆ0-100ï¼‰

    Args:
        context: åŒ…å«åŸºæœ¬é¢æŒ‡æ ‡çš„å­—å…¸

    Returns:
        åŸºæœ¬é¢å¾—åˆ† (0-100)
    """
    score = 50  # åŸºç¡€åˆ†

    try:
        # ROE - æƒé‡ 25%
        roe = _to_float(context.get('roe'))
        if roe is not None:
            if roe >= 20:
                score += 20
            elif roe >= 15:
                score += 15
            elif roe >= 10:
                score += 10
            elif roe < 5:
                score -= 15

        # PE Ratio - æƒé‡ 20%
        pe = _to_float(context.get('pe_ratio'))
        if pe is not None:
            if pe < 15:
                score += 20
            elif pe < 25:
                score += 15
            elif pe < 35:
                score += 5
            elif pe > 50:
                score -= 20

        # Revenue Growth (CAGR) - æƒé‡ 25%
        growth = _to_float(context.get('revenue_growth_cagr'))
        if growth is not None:
            growth_pct = growth * 100 if growth < 1 else growth
            if growth_pct >= 20:
                score += 25
            elif growth_pct >= 15:
                score += 20
            elif growth_pct >= 10:
                score += 15
            elif growth_pct >= 5:
                score += 10
            elif growth_pct < 0:
                score -= 20

        # Debt-to-Equity - æƒé‡ 15%
        debt_to_equity = _to_float(context.get('debt_to_equity'))
        if debt_to_equity is not None:
            if debt_to_equity < 30:
                score += 15
            elif debt_to_equity < 50:
                score += 10
            elif debt_to_equity < 80:
                score += 5
            else:  # >= 80
                score -= 15

        # PB Ratio - æƒé‡ 10%
        pb = _to_float(context.get('pb_ratio'))
        if pb is not None:
            if pb < 2:
                score += 10
            elif pb < 3:
                score += 5
            elif pb > 8:
                score -= 10

        # PEG Ratio - æƒé‡ 5%
        peg = _to_float(context.get('peg_ratio'))
        if peg is not None:
            if peg < 1:
                score += 5
            elif peg > 2:
                score -= 5

    except Exception as e:
        logger.warning(f"Error calculating fundamental score: {e}")

    return max(0, min(100, int(score)))
